---
layout: about
title: About
permalink: /
description: 

profile:
  align: left
  image: me2.png
  image_circular: true
  address: 

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

Assistant Professor, <a href="https://www.wm.edu/">William & Mary</a><br/>
jwang80 [at] wm.edu, jindongwang [at] outlook.com<br>
Integrated Science Center 2273, Williamsburg, VA<br>
[Google scholar](https://scholar.google.com/citations?&user=hBZ_tKsAAAAJ&view_op=list_works&sortby=pubdate) | [DBLP](https://dblp.org/pid/19/2969-1.html) | [Github](https://github.com/jindongwang) || [Twitter/X](https://twitter.com/jd92wang) | [Zhihu](https://www.zhihu.com/people/jindongwang) | [Wechat](http://jd92.wang/assets/img/wechat_public_account.jpg) | [Bilibili](https://space.bilibili.com/477087194) || [CV](https://go.jd92.wang/cv) [CV (Chinese)](https://go.jd92.wang/cvchinese)

Dr. Jindong Wang is a Tenure-Track Assistant Professor at William & Mary since 2025. Previously, he has been a Senior Researcher in Microsoft Research Asia for 5.5 years. His research interest includes machine learning, large language and foundation models, and AI for social science. He serves as the associate editor of IEEE Transactions on Neural Networks and Learning Systems (TNNLS), guest editor for ACM Transactions on Intelligent Systems and Technology (TIST), area chair for ICML, NeurIPS, ICLR, KDD, ACMMM, and ACML, SPC of IJCAI and AAAI. He has published over 60 papers with 15000+ citations at leading conferences and journals such as ICML, ICLR, NeurIPS, TPAMI, IJCV etc. His research is reported by [Forbes](https://www.forbes.com/sites/lanceeliot/2023/11/11/the-answer-to-why-emotionally-worded-prompts-can-goose-generative-ai-into-better-answers-and-how-to-spur-a-decidedly-positive-rise-out-of-ai/?sh=38038fb137e5), [MIT Technology Review](https://www.mittrchina.com/news/detail/13596), and other international media. Since 2022, he has been selected by Stanford University as one of the [World's Top 2% Scientists](https://ecebm.com/2023/10/04/stanford-university-names-worlds-top-2-scientists-2023/) and one of the [Most Influential AI Scholars](https://www.aminer.cn/ai2000?domain_ids=5dc122672ebaa6faa962c2a4) by AMiner. He received best and outstanding papers awards at several internation conferences and workshops. He published a book [Introduction to Transfer Learning](http://jd92.wang/tlbook). He gave tutorials at [IJCAI'22](https://dgresearch.github.io/), [WSDM'23](https://dgresearch.github.io/), [KDD'23](https://mltrust.github.io/), [AAAI'24](https://ood-timeseries.github.io/), and AAAI'25. He leads several impactful open-source projects, including [transferlearning](https://github.com/jindongwang/transferlearning), [PromptBench](https://github.com/microsoft/promptbench), [torchSSL](https://github.com/torchssl/torchssl), and [USB](https://github.com/microsoft/Semi-superised-learning), which received over 16K stars on Github. 
He obtained his Ph.D from University of Chinese Academy of Sciences in 2019 with the excellent PhD thesis award and a bachelor's degree from North China University of Technology in 2014.

**PhD application in 25 Fall:** [[Visit this page](https://jd92wang.notion.site/Professor-Jindong-Wang-from-William-Mary-is-Recruiting-Fully-Funded-PhD-Students-Interns-for-Fall-12eb4ea70d8e803cadebd1a9b75fd739?pvs=4)]  [[中文版](https://zhuanlan.zhihu.com/p/4827065042)] | [Internship or collaboration](https://forms.gle/zRcWP49qF9aR1VXW8)

**Research interest:** (See this [page](https://jd92.wang/research/) for more details)
- Machine learning: To make ML systems more robust, trustworthy, and responsible. Related topics include: robust machine learning, OOD / domain generalization, transfer learning, semi-supervised learning, federated learning, and related applications. New: ML with foundation models.
- Philosophy of language models: We mainly focus on understanding the potential and limitation of large foundation models. Related topics: LLM [evaluation](https://llm-eval.github.io/) and [enhancement](https://llm-enhance.github.io/), and agent behavior.
- AI for social sciences: How to measure the impact of generative AI on different domains? How to assist interdisciplinary domains using powerful AI models? How to use existing social science knowledge to help us better understand AI behaviors?

